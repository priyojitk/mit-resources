{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "thesis_cnn-lstm-ae-pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bML7SLsugflo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import abc\n",
        "import logging\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "class Algorithm(metaclass=abc.ABCMeta):\n",
        "    def __init__(self, module_name, name, seed, details=False):\n",
        "        self.logger = logging.getLogger(module_name)\n",
        "        self.name = name\n",
        "        self.seed = seed\n",
        "        self.details = details\n",
        "        self.prediction_details = {}\n",
        "        self.history = {}\n",
        "\n",
        "        if self.seed is not None:\n",
        "            random.seed(seed)\n",
        "            np.random.seed(seed)\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.name\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def fit(self, X):\n",
        "        \"\"\"\n",
        "        Train the algorithm on the given dataset\n",
        "        \"\"\"\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        :return anomaly score\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "class PyTorchUtils(metaclass=abc.ABCMeta):\n",
        "    def __init__(self, seed, gpu):\n",
        "        self.gpu = gpu\n",
        "        self.seed = seed\n",
        "        if self.seed is not None:\n",
        "            torch.manual_seed(self.seed)\n",
        "            torch.cuda.manual_seed(self.seed)\n",
        "        self.framework = 0\n",
        "\n",
        "    @property\n",
        "    def device(self):\n",
        "        return torch.device('cuda:{self.gpu}' if torch.cuda.is_available() and self.gpu is not None else 'cpu')\n",
        "\n",
        "    def to_var(self, t, **kwargs):\n",
        "        # ToDo: check whether cuda Variable.\n",
        "        t = t.to(self.device)\n",
        "        return Variable(t, **kwargs)\n",
        "\n",
        "    def to_device(self, model):\n",
        "        model.to(self.device)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Jg7hDpKSfRz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "632153b6-2c41-4981-bf11-9429f6c21ded"
      },
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from scipy.stats import multivariate_normal\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from tqdm import trange\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "!git clone https://github.com/priyojitk/mit-resources.git yahoo_dataset\n",
        "file_path = '/content/yahoo_dataset/'\n",
        "import sys\n",
        "sys.path.append(file_path)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'yahoo_dataset' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBPFtxmVSvBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, fbeta_score\n",
        "from sklearn.metrics import precision_recall_fscore_support as prf\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "\n",
        "def get_accuracy_precision_recall_fscore(y_true: list, y_pred: list):\n",
        "        accuracy = accuracy_score(y_true, y_pred)\n",
        "        # warn_for=() avoids log warnings for any result being zero\n",
        "        precision, recall, f_score, _ = prf(y_true, y_pred, average='binary', warn_for=())\n",
        "        if precision == 0 and recall == 0:\n",
        "            f01_score = 0\n",
        "        else:\n",
        "            f01_score = fbeta_score(y_true, y_pred, average='binary', beta=0.1)\n",
        "        return accuracy, precision, recall, f_score, f01_score\n",
        "\n",
        "# accuracy, precision, recall, f_score, f01_score = get_accuracy_precision_recall_fscore(_test['is_anomaly'], pred_y)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAyOm1lHS3im",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def threshold(score):\n",
        "    return np.nanmean(score) + 2 * np.nanstd(score)\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEmAciKFDa0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, kernel_size, sequence_length, input_dim, latent_dim, num_layers):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.sequence_length = sequence_length\n",
        "        self.conv_padding=int((kernel_size - 1)/2) #in this way the output has the same size\n",
        "        self.maxpool_kernel_size = 3\n",
        "        self.maxpool_padding=int((self.maxpool_kernel_size - 1)/2) #in this way the output has the same size\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv1d(1, 5, kernel_size=kernel_size, padding = self.conv_padding),\n",
        "            nn.MaxPool1d(self.maxpool_kernel_size, stride=1, padding = self.maxpool_padding),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv1d(5, 25, kernel_size=kernel_size, padding = self.conv_padding),\n",
        "            nn.MaxPool1d(self.maxpool_kernel_size, stride=1, padding = self.maxpool_padding),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "            \n",
        "        self.decoder = nn.Sequential(             \n",
        "            nn.ConvTranspose1d(25, 5, kernel_size=kernel_size, padding = self.conv_padding),\n",
        "            nn.MaxPool1d(self.maxpool_kernel_size, stride=1, padding = self.maxpool_padding),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose1d(5, 1, kernel_size=kernel_size, padding = self.conv_padding),\n",
        "            nn.MaxPool1d(self.maxpool_kernel_size, stride=1, padding = self.maxpool_padding),\n",
        "            nn.ReLU(True))\n",
        "        \n",
        "        self.input_dim = input_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.encoder1 = nn.LSTM(self.input_dim, self.latent_dim, num_layers=self.num_layers[0])\n",
        "\n",
        "        self.decoder1 = nn.LSTM(self.latent_dim, self.input_dim, num_layers=self.num_layers[1])\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        x = x.view(batch_size, 1, self.sequence_length) #for convolution\n",
        "        x = self.encoder(x.float())\n",
        "        x = self.decoder(x)\n",
        "        x = x.view(batch_size, self.sequence_length, 1) #for lstm\n",
        "        # print(x.shape)\n",
        "        input = x\n",
        "        sequence_length = input.shape[1]\n",
        "\n",
        "        encoded, (last_hidden, _) = self.encoder1(input.float())\n",
        "        # print(encoded.shape)\n",
        "        decoder_input = encoded[:, -1:].repeat(1, sequence_length, 1)\n",
        "        decoded, _ = self.decoder1(decoder_input)  \n",
        "        return decoded"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgIOIaNzC-A0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  model =  Autoencoder(kernel_size = 5, sequence_length = 10, input_dim=1, latent_dim=15, num_layers=(1, 1))\n",
        "# model\n",
        "# input = torch.randn(20, 10, 1)\n",
        "# batch_size = input.shape[0]\n",
        "# sequence_length = input.shape[1]\n",
        "# model(input).shape"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr35XyIdiuxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CLSTMED(Algorithm, PyTorchUtils):\n",
        "    def __init__(self, name: str = 'LSTM-ED',\n",
        "                 num_epochs: int = 10, \n",
        "                 batch_size: int = 20, \n",
        "                 lr: float = 1e-3,\n",
        "                 hidden_size: int = 5,\n",
        "                 sequence_length: int = 48,\n",
        "                 train_gaussian_percentage: float = 0.2,\n",
        "                 n_layers: tuple = (1, 1), \n",
        "                 use_bias: tuple = (True, True),\n",
        "                 dropout: tuple = (0, 0),\n",
        "                 seed: int = 1,\n",
        "                 gpu: int = None,\n",
        "                 details=True):\n",
        "        \n",
        "        Algorithm.__init__(self, __name__, name, seed, details=details)\n",
        "        if self.seed is not None:\n",
        "            random.seed(seed)\n",
        "            np.random.seed(seed)\n",
        "        \n",
        "        PyTorchUtils.__init__(self, seed, gpu)\n",
        "        \n",
        "        self.num_epochs = num_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.lr = lr\n",
        "        self.hidden_size = hidden_size\n",
        "        self.sequence_length = sequence_length\n",
        "        self.train_gaussian_percentage = train_gaussian_percentage\n",
        "\n",
        "        self.n_layers = n_layers\n",
        "        self.use_bias = use_bias\n",
        "        self.dropout = dropout \n",
        "        self.mean, self.cov = None, None\n",
        "\n",
        "\n",
        "    def fit(self, X: pd.DataFrame):\n",
        "        \n",
        "        X.interpolate(inplace=True) #\n",
        "        X.bfill(inplace=True) #backward fill values\n",
        "        data = X.values\n",
        "        sequences = [data[i:i + self.sequence_length] for i in range(data.shape[0] - self.sequence_length + 1)]\n",
        "        indices = np.random.permutation(len(sequences)) \n",
        "        \n",
        "        split_point = int(self.train_gaussian_percentage * len(sequences))\n",
        "#         self.logger.info(f'len of split_point : {(split_point)}')\n",
        "        train_loader = DataLoader(dataset=sequences, batch_size=self.batch_size, drop_last=True,\n",
        "                                  sampler=SubsetRandomSampler(indices[:-split_point]), pin_memory=True)\n",
        "        train_gaussian_loader = DataLoader(dataset=sequences, batch_size=self.batch_size, drop_last=True,\n",
        "                                           sampler=SubsetRandomSampler(indices[-split_point:]), pin_memory=True)\n",
        "\n",
        "        self.clstmed = Autoencoder(kernel_size = 5, sequence_length = self.sequence_length, \n",
        "                                   input_dim=1, latent_dim=self.hidden_size, num_layers=self.n_layers)\n",
        "        self.to_device(self.clstmed)\n",
        "\n",
        "#         self.logger.info(f'X.shape : {X.shape}')\n",
        "        self.to_device(self.clstmed)\n",
        "        optimizer = torch.optim.Adam(self.clstmed.parameters(), lr=self.lr)\n",
        "\n",
        "        self.clstmed.train() #set to training mode=True\n",
        "        self.history['train_loss'] = []\n",
        "        self.history['val_loss'] = []\n",
        "        \n",
        "        for epoch in trange(self.num_epochs): #self.num_epochs\n",
        "            self.clstmed.train() #set to training mode=True\n",
        "            train_batch_loss = []\n",
        "            for ts_batch in train_loader:\n",
        "                # print(\"ts_batch size\", ts_batch.shape) #[20, 24, 1]\n",
        "                output = self.clstmed(self.to_var(ts_batch.float()))\n",
        "                loss = nn.MSELoss(reduction='mean')(output, self.to_var(ts_batch.float())) \n",
        "                self.clstmed.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                train_batch_loss.append(loss.item())\n",
        "            train_loss = sum(train_batch_loss)/len(train_batch_loss)\n",
        "            self.history['train_loss'].append(train_loss)\n",
        "        \n",
        "\n",
        "            self.clstmed.eval()\n",
        "            val_batch_loss = []\n",
        "            for ts_batch in train_gaussian_loader:\n",
        "                output = self.clstmed(self.to_var(ts_batch))\n",
        "                val_loss = nn.MSELoss(reduction='mean')(output, self.to_var(ts_batch.float())) \n",
        "                val_batch_loss.append(val_loss.item())\n",
        "            self.history['val_loss'].append(sum(val_batch_loss)/len(val_batch_loss))\n",
        "\n",
        "        self.clstmed.eval()\n",
        "        error_vectors = []\n",
        "        count = 0\n",
        "        for ts_batch in train_gaussian_loader:\n",
        "            output = self.clstmed(self.to_var(ts_batch))\n",
        "            error = nn.L1Loss(reduction='none')(output, self.to_var(ts_batch.float())) #MAE\n",
        "            error_vectors += list(error.view(-1, X.shape[1]).data.cpu().numpy())\n",
        "\n",
        "        self.mean = np.mean(error_vectors, axis=0)\n",
        "        self.cov = np.cov(error_vectors, rowvar=False)\n",
        "        # logging.info(f'Mean error in evaluation : {self.mean}')\n",
        "        # logging.info(f'Mean cov in evaluation : {self.cov}')\n",
        "\n",
        "    def predict(self, X: pd.DataFrame):\n",
        "        X.interpolate(inplace=True)\n",
        "        X.bfill(inplace=True)\n",
        "        data = X.values\n",
        "        sequences = [data[i:i + self.sequence_length] for i in range(data.shape[0] - self.sequence_length + 1)]\n",
        "        data_loader = DataLoader(dataset=sequences, batch_size=self.batch_size, shuffle=False, drop_last=False)\n",
        "\n",
        "        self.clstmed.eval()\n",
        "        mvnormal = multivariate_normal(self.mean, self.cov, allow_singular=True)\n",
        "        scores = []\n",
        "        outputs = []\n",
        "        errors = []\n",
        "        for idx, ts in enumerate(data_loader):\n",
        "            output = self.clstmed(self.to_var(ts))\n",
        "            error = nn.L1Loss(reduction='none')(output, self.to_var(ts.float()))\n",
        "            score = -mvnormal.logpdf(error.view(-1, X.shape[1]).data.cpu().numpy())\n",
        "            # score = mvnormal.pdf(error.view(-1, X.shape[1]).data.cpu().numpy())\n",
        "            scores.append(score.reshape(ts.size(0), self.sequence_length)) #ts.size() == batch size\n",
        "            if self.details:\n",
        "                outputs.append(output.data.numpy())\n",
        "                errors.append(error.data.numpy())\n",
        "\n",
        "        # stores seq_len-many scores per timestamp and averages them\n",
        "        scores = np.concatenate(scores)\n",
        "        self.logger.debug(f'score shape 2 , {len(scores)}')\n",
        "        lattice = np.full((self.sequence_length, data.shape[0]), np.nan)\n",
        "        self.logger.debug(f'lattice shape 1 , {lattice.shape}')\n",
        "        for i, score in enumerate(scores):\n",
        "            lattice[i % self.sequence_length, i:i + self.sequence_length] = score\n",
        "        scores = np.nanmean(lattice, axis=0)\n",
        "        self.logger.debug(f'score shape 3 : {scores.shape}')\n",
        "\n",
        "        return scores\n",
        "\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nMo4ZLL6xIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_specificity(actual_y, pred_y):\n",
        "    tn, fp, fn, tp = confusion_matrix(actual_y, pred_y).ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "    return specificity"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebaDh9K_WA1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_accuracy, avg_precision, avg_recall, avg_f_score, avg_f01_score = 0, 0, 0, 0, 0\n",
        "avg_auc = 0\n",
        "avg_specificity = 0\n",
        "A1 = 67\n",
        "A4 = 100\n",
        "no_of_dataset = A1\n",
        "zero_anomaly_test = 0"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTeZ16Pjew4X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "027acfdf-9b3b-4e34-d89e-7e4aaac62af3"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "for ind in range(1, no_of_dataset + 1):\n",
        "\n",
        "    print('\\nDataset ', ind)\n",
        "    logging.info(f'\\n\\n=============\\n Dataset {ind} : \\n=============')\n",
        "\n",
        "    df = pd.read_csv(f'{file_path}dataset/ydata-labeled-time-series-anomalies-v1_0/A1Benchmark/real_{ind}.csv', index_col='timestamp')\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    df['value'] = df['value'].astype(np.float64)\n",
        "\n",
        "    # Normalize the  data (center around 0 and scale to remove the variance).\n",
        "    scaler = StandardScaler()\n",
        "    df['value'] = scaler.fit_transform(df['value'].values.reshape(-1, 1))\n",
        "\n",
        "    len_of_data = df.shape[0]\n",
        "    # _train = df[0:500] \n",
        "    # _test = df[500:]\n",
        "\n",
        "    _train = df[0:int(len_of_data * 0.4)] # 40 percent when index is not range(1, N)\n",
        "    _test = df[int(len_of_data * 0.4):] # 60 percent\n",
        "    # _train = df.head(int(len_of_data * 0.5))\n",
        "    # _test = df.tail(int(len_of_data * 0.5)) # 60 percent\n",
        "    print('length of training set :', len(_train))\n",
        "    print('length of test set :', len(_test))\n",
        "\n",
        "    #If there is no anomaly in 'test' data or whole data ignore the dataset\n",
        "    anomaly_count_test = len(_test[_test['is_anomaly'] == 1])\n",
        "    # anomaly_count_test = len(_test[_test['anomaly'] == 1])\n",
        "    print('#anomaly in test set :', anomaly_count_test)\n",
        "    if anomaly_count_test == 0:\n",
        "        zero_anomaly_test += 1\n",
        "        continue\n",
        "\n",
        "    model = CLSTMED(num_epochs=30, sequence_length=10, hidden_size=10, n_layers=(1, 1))#56\n",
        "    model.fit(_train[['value']].copy())\n",
        "\n",
        "    scores = model.predict(_test[['value']].copy())\n",
        "    th = threshold(scores)\n",
        "    pred_y = np.where(np.array(scores) > th, 1, 0) \n",
        "\n",
        "    accuracy, precision, recall, f_score, f01_score = get_accuracy_precision_recall_fscore(_test['is_anomaly'], pred_y)\n",
        "    auc = roc_auc_score(_test['is_anomaly'], pred_y)\n",
        "    specificity = get_specificity(_test['is_anomaly'], pred_y)\n",
        "\n",
        "    print(f'Accuracy : {accuracy}')\n",
        "    print(f'Precision : {precision}')\n",
        "    print(f'recall : {recall}')\n",
        "    print(f'f_score : {f_score}')\n",
        "    print(f'f01_score : {f01_score}')\n",
        "    print(f'auc : {auc}')\n",
        "    print(f'specificity : {specificity}')\n",
        "    \n",
        "\n",
        "    avg_accuracy += accuracy\n",
        "    avg_precision += precision\n",
        "    avg_recall += recall\n",
        "    avg_f_score += f_score\n",
        "    avg_f01_score += f01_score\n",
        "    avg_auc += auc\n",
        "    avg_specificity += specificity\n",
        "\n",
        "denominator = (no_of_dataset - zero_anomaly_test)\n",
        "print(f'Avg Accuracy : {avg_accuracy / denominator }')\n",
        "print(f'Avg Precision : {avg_precision / denominator }')\n",
        "print(f'Avg recall : {avg_recall / denominator }')\n",
        "print(f'Avg f_score : {avg_f_score / denominator }')\n",
        "print(f'Avg f01_score : {avg_f01_score / denominator }')\n",
        "print(f'Avg auc : {avg_auc / denominator }')\n",
        "print(f'Avg specificity : {avg_specificity / denominator }')\n",
        "print(f\"--- {(time.time() - start_time)/60} minutes ---\" )\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset  1\n",
            "length of training set : 568\n",
            "length of test set : 852\n",
            "#anomaly in test set : 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.19it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9870892018779343\n",
            "Precision : 0.15384615384615385\n",
            "recall : 1.0\n",
            "f_score : 0.2666666666666667\n",
            "f01_score : 0.15514592933947774\n",
            "auc : 0.9935294117647059\n",
            "specificity : 0.9870588235294118\n",
            "\n",
            "Dataset  2\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9872685185185185\n",
            "Precision : 1.0\n",
            "recall : 0.3125\n",
            "f_score : 0.47619047619047616\n",
            "f01_score : 0.9786821705426356\n",
            "auc : 0.65625\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  3\n",
            "length of training set : 584\n",
            "length of test set : 877\n",
            "#anomaly in test set : 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.10it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9942987457240593\n",
            "Precision : 1.0\n",
            "recall : 0.6428571428571429\n",
            "f_score : 0.782608695652174\n",
            "f01_score : 0.9945295404814004\n",
            "auc : 0.8214285714285714\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  4\n",
            "length of training set : 569\n",
            "length of test set : 854\n",
            "#anomaly in test set : 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 1.0\n",
            "Precision : 1.0\n",
            "recall : 1.0\n",
            "f_score : 1.0\n",
            "f01_score : 1.0\n",
            "auc : 1.0\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  5\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 0\n",
            "\n",
            "Dataset  6\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9988425925925926\n",
            "Precision : 1.0\n",
            "recall : 0.875\n",
            "f_score : 0.9333333333333333\n",
            "f01_score : 0.998587570621469\n",
            "auc : 0.9375\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  7\n",
            "length of training set : 569\n",
            "length of test set : 854\n",
            "#anomaly in test set : 38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.955503512880562\n",
            "Precision : 0.5\n",
            "recall : 0.07894736842105263\n",
            "f_score : 0.13636363636363635\n",
            "f01_score : 0.4749216300940438\n",
            "auc : 0.5376354489164087\n",
            "specificity : 0.9963235294117647\n",
            "\n",
            "Dataset  8\n",
            "length of training set : 568\n",
            "length of test set : 852\n",
            "#anomaly in test set : 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9988262910798122\n",
            "Precision : 0.9090909090909091\n",
            "recall : 1.0\n",
            "f_score : 0.9523809523809523\n",
            "f01_score : 0.9099099099099099\n",
            "auc : 0.9994061757719714\n",
            "specificity : 0.998812351543943\n",
            "\n",
            "Dataset  9\n",
            "length of training set : 584\n",
            "length of test set : 877\n",
            "#anomaly in test set : 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.12it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9931584948688712\n",
            "Precision : 1.0\n",
            "recall : 0.25\n",
            "f_score : 0.4\n",
            "f01_score : 0.9711538461538461\n",
            "auc : 0.625\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  10\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 1.0\n",
            "Precision : 1.0\n",
            "recall : 1.0\n",
            "f_score : 1.0\n",
            "f01_score : 1.0\n",
            "auc : 1.0\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  11\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9849537037037037\n",
            "Precision : 1.0\n",
            "recall : 0.3157894736842105\n",
            "f_score : 0.4799999999999999\n",
            "f01_score : 0.9789983844911146\n",
            "auc : 0.6578947368421053\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  12\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9988425925925926\n",
            "Precision : 1.0\n",
            "recall : 0.5\n",
            "f_score : 0.6666666666666666\n",
            "f01_score : 0.9901960784313726\n",
            "auc : 0.75\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  13\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9965277777777778\n",
            "Precision : 1.0\n",
            "recall : 0.6666666666666666\n",
            "f_score : 0.8\n",
            "f01_score : 0.9950738916256158\n",
            "auc : 0.8333333333333333\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  14\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 0\n",
            "\n",
            "Dataset  15\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9965277777777778\n",
            "Precision : 1.0\n",
            "recall : 0.625\n",
            "f_score : 0.7692307692307693\n",
            "f01_score : 0.9940944881889763\n",
            "auc : 0.8125\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  16\n",
            "length of training set : 584\n",
            "length of test set : 877\n",
            "#anomaly in test set : 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.12it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9977194982896237\n",
            "Precision : 1.0\n",
            "recall : 0.3333333333333333\n",
            "f_score : 0.5\n",
            "f01_score : 0.9805825242718447\n",
            "auc : 0.6666666666666666\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  17\n",
            "length of training set : 569\n",
            "length of test set : 855\n",
            "#anomaly in test set : 227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.7941520467836257\n",
            "Precision : 1.0\n",
            "recall : 0.22466960352422907\n",
            "f_score : 0.3669064748201439\n",
            "f01_score : 0.9669607659095175\n",
            "auc : 0.6123348017621145\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  18\n",
            "length of training set : 584\n",
            "length of test set : 877\n",
            "#anomaly in test set : 0\n",
            "\n",
            "Dataset  19\n",
            "length of training set : 569\n",
            "length of test set : 855\n",
            "#anomaly in test set : 227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:08<00:00,  3.34it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.7672514619883041\n",
            "Precision : 1.0\n",
            "recall : 0.12334801762114538\n",
            "f_score : 0.2196078431372549\n",
            "f01_score : 0.9342583415923357\n",
            "auc : 0.5616740088105727\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  20\n",
            "length of training set : 568\n",
            "length of test set : 854\n",
            "#anomaly in test set : 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.990632318501171\n",
            "Precision : 1.0\n",
            "recall : 0.1111111111111111\n",
            "f_score : 0.19999999999999998\n",
            "f01_score : 0.926605504587156\n",
            "auc : 0.5555555555555556\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  21\n",
            "length of training set : 568\n",
            "length of test set : 852\n",
            "#anomaly in test set : 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9988262910798122\n",
            "Precision : 1.0\n",
            "recall : 0.8333333333333334\n",
            "f_score : 0.9090909090909091\n",
            "f01_score : 0.9980237154150197\n",
            "auc : 0.9166666666666667\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  22\n",
            "length of training set : 568\n",
            "length of test set : 852\n",
            "#anomaly in test set : 63\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9565727699530516\n",
            "Precision : 1.0\n",
            "recall : 0.4126984126984127\n",
            "f_score : 0.5842696629213483\n",
            "f01_score : 0.9861058956064589\n",
            "auc : 0.7063492063492063\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  23\n",
            "length of training set : 568\n",
            "length of test set : 852\n",
            "#anomaly in test set : 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.994131455399061\n",
            "Precision : 0.6428571428571429\n",
            "recall : 1.0\n",
            "f_score : 0.782608695652174\n",
            "f01_score : 0.6451383960255501\n",
            "auc : 0.9970344009489918\n",
            "specificity : 0.9940688018979834\n",
            "\n",
            "Dataset  24\n",
            "length of training set : 584\n",
            "length of test set : 877\n",
            "#anomaly in test set : 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 1.0\n",
            "Precision : 1.0\n",
            "recall : 1.0\n",
            "f_score : 1.0\n",
            "f01_score : 1.0\n",
            "auc : 1.0\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  25\n",
            "length of training set : 574\n",
            "length of test set : 861\n",
            "#anomaly in test set : 43\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9988385598141696\n",
            "Precision : 1.0\n",
            "recall : 0.9767441860465116\n",
            "f_score : 0.988235294117647\n",
            "f01_score : 0.9997643176997407\n",
            "auc : 0.9883720930232558\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  26\n",
            "length of training set : 574\n",
            "length of test set : 861\n",
            "#anomaly in test set : 75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.8896631823461092\n",
            "Precision : 0.0\n",
            "recall : 0.0\n",
            "f_score : 0.0\n",
            "f01_score : 0\n",
            "auc : 0.4872773536895674\n",
            "specificity : 0.9745547073791349\n",
            "\n",
            "Dataset  27\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 1.0\n",
            "Precision : 1.0\n",
            "recall : 1.0\n",
            "f_score : 1.0\n",
            "f01_score : 1.0\n",
            "auc : 1.0\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  28\n",
            "length of training set : 576\n",
            "length of test set : 865\n",
            "#anomaly in test set : 81\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.8658959537572254\n",
            "Precision : 0.02702702702702703\n",
            "recall : 0.012345679012345678\n",
            "f_score : 0.01694915254237288\n",
            "f01_score : 0.026712509918011107\n",
            "auc : 0.4832136558327035\n",
            "specificity : 0.9540816326530612\n",
            "\n",
            "Dataset  29\n",
            "length of training set : 576\n",
            "length of test set : 865\n",
            "#anomaly in test set : 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9942196531791907\n",
            "Precision : 0.5714285714285714\n",
            "recall : 0.6666666666666666\n",
            "f_score : 0.6153846153846153\n",
            "f01_score : 0.5722379603399433\n",
            "auc : 0.8315871168024834\n",
            "specificity : 0.9965075669383003\n",
            "\n",
            "Dataset  30\n",
            "length of training set : 584\n",
            "length of test set : 877\n",
            "#anomaly in test set : 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.06it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9988597491448119\n",
            "Precision : 1.0\n",
            "recall : 0.875\n",
            "f_score : 0.9333333333333333\n",
            "f01_score : 0.998587570621469\n",
            "auc : 0.9375\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  31\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9428238039673279\n",
            "Precision : 0.29508196721311475\n",
            "recall : 0.75\n",
            "f_score : 0.42352941176470593\n",
            "f01_score : 0.2968647942521228\n",
            "auc : 0.8491896758703482\n",
            "specificity : 0.9483793517406963\n",
            "\n",
            "Dataset  32\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 47\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9148191365227538\n",
            "Precision : 0.30303030303030304\n",
            "recall : 0.425531914893617\n",
            "f_score : 0.35398230088495575\n",
            "f01_score : 0.30389649465924473\n",
            "auc : 0.6843708957184134\n",
            "specificity : 0.9432098765432099\n",
            "\n",
            "Dataset  33\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9988425925925926\n",
            "Precision : 1.0\n",
            "recall : 0.5\n",
            "f_score : 0.6666666666666666\n",
            "f01_score : 0.9901960784313726\n",
            "auc : 0.75\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  34\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9964994165694282\n",
            "Precision : 0.7\n",
            "recall : 1.0\n",
            "f_score : 0.8235294117647058\n",
            "f01_score : 0.702085402184707\n",
            "auc : 0.998235294117647\n",
            "specificity : 0.9964705882352941\n",
            "\n",
            "Dataset  35\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 0\n",
            "\n",
            "Dataset  36\n",
            "length of training set : 584\n",
            "length of test set : 877\n",
            "#anomaly in test set : 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.08it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9965792474344356\n",
            "Precision : 0.25\n",
            "recall : 1.0\n",
            "f_score : 0.4\n",
            "f01_score : 0.2518703241895262\n",
            "auc : 0.9982876712328766\n",
            "specificity : 0.9965753424657534\n",
            "\n",
            "Dataset  37\n",
            "length of training set : 573\n",
            "length of test set : 861\n",
            "#anomaly in test set : 34\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9465737514518002\n",
            "Precision : 0.125\n",
            "recall : 0.058823529411764705\n",
            "f_score : 0.07999999999999999\n",
            "f01_score : 0.12362301101591187\n",
            "auc : 0.5209474358062451\n",
            "specificity : 0.9830713422007256\n",
            "\n",
            "Dataset  38\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9918319719953326\n",
            "Precision : 0.6666666666666666\n",
            "recall : 0.4444444444444444\n",
            "f_score : 0.5333333333333333\n",
            "f01_score : 0.6633825944170771\n",
            "auc : 0.7210429769392033\n",
            "specificity : 0.9976415094339622\n",
            "\n",
            "Dataset  39\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9964994165694282\n",
            "Precision : 1.0\n",
            "recall : 0.625\n",
            "f_score : 0.7692307692307693\n",
            "f01_score : 0.9940944881889763\n",
            "auc : 0.8125\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  40\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 80\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.8763127187864644\n",
            "Precision : 0.03571428571428571\n",
            "recall : 0.0125\n",
            "f_score : 0.01851851851851852\n",
            "f01_score : 0.03506944444444444\n",
            "auc : 0.4888754826254826\n",
            "specificity : 0.9652509652509652\n",
            "\n",
            "Dataset  41\n",
            "length of training set : 574\n",
            "length of test set : 861\n",
            "#anomaly in test set : 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9988385598141696\n",
            "Precision : 0.6666666666666666\n",
            "recall : 1.0\n",
            "f_score : 0.8\n",
            "f01_score : 0.6688741721854305\n",
            "auc : 0.9994179278230501\n",
            "specificity : 0.9988358556461001\n",
            "\n",
            "Dataset  42\n",
            "length of training set : 576\n",
            "length of test set : 864\n",
            "#anomaly in test set : 44\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9745370370370371\n",
            "Precision : 1.0\n",
            "recall : 0.5\n",
            "f_score : 0.6666666666666666\n",
            "f01_score : 0.9901960784313726\n",
            "auc : 0.75\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  43\n",
            "length of training set : 576\n",
            "length of test set : 864\n",
            "#anomaly in test set : 27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9722222222222222\n",
            "Precision : 1.0\n",
            "recall : 0.1111111111111111\n",
            "f_score : 0.19999999999999998\n",
            "f01_score : 0.926605504587156\n",
            "auc : 0.5555555555555556\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  44\n",
            "length of training set : 584\n",
            "length of test set : 877\n",
            "#anomaly in test set : 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9486887115165337\n",
            "Precision : 0.022222222222222223\n",
            "recall : 0.5\n",
            "f_score : 0.0425531914893617\n",
            "f01_score : 0.02243447356730342\n",
            "auc : 0.7248571428571429\n",
            "specificity : 0.9497142857142857\n",
            "\n",
            "Dataset  45\n",
            "length of training set : 576\n",
            "length of test set : 864\n",
            "#anomaly in test set : 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 1.0\n",
            "Precision : 1.0\n",
            "recall : 1.0\n",
            "f_score : 1.0\n",
            "f01_score : 1.0\n",
            "auc : 1.0\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  46\n",
            "length of training set : 576\n",
            "length of test set : 865\n",
            "#anomaly in test set : 109\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9895953757225433\n",
            "Precision : 1.0\n",
            "recall : 0.9174311926605505\n",
            "f_score : 0.9569377990430622\n",
            "f01_score : 0.999109704223959\n",
            "auc : 0.9587155963302753\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  47\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9474912485414235\n",
            "Precision : 0.02702702702702703\n",
            "recall : 0.1\n",
            "f_score : 0.0425531914893617\n",
            "f01_score : 0.027223719676549865\n",
            "auc : 0.5287485242030697\n",
            "specificity : 0.9574970484061394\n",
            "\n",
            "Dataset  48\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 0\n",
            "\n",
            "Dataset  49\n",
            "length of training set : 584\n",
            "length of test set : 877\n",
            "#anomaly in test set : 0\n",
            "\n",
            "Dataset  50\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9965277777777778\n",
            "Precision : 0.7\n",
            "recall : 1.0\n",
            "f_score : 0.8235294117647058\n",
            "f01_score : 0.702085402184707\n",
            "auc : 0.998249708284714\n",
            "specificity : 0.9964994165694282\n",
            "\n",
            "Dataset  51\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9918319719953326\n",
            "Precision : 0.3333333333333333\n",
            "recall : 0.75\n",
            "f_score : 0.46153846153846156\n",
            "f01_score : 0.33517699115044247\n",
            "auc : 0.871483001172333\n",
            "specificity : 0.9929660023446659\n",
            "\n",
            "Dataset  52\n",
            "length of training set : 572\n",
            "length of test set : 860\n",
            "#anomaly in test set : 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9941860465116279\n",
            "Precision : 1.0\n",
            "recall : 0.4444444444444444\n",
            "f_score : 0.6153846153846153\n",
            "f01_score : 0.9877750611246944\n",
            "auc : 0.7222222222222222\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  53\n",
            "length of training set : 584\n",
            "length of test set : 877\n",
            "#anomaly in test set : 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.18it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 1.0\n",
            "Precision : 1.0\n",
            "recall : 1.0\n",
            "f_score : 1.0\n",
            "f01_score : 1.0\n",
            "auc : 1.0\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  54\n",
            "length of training set : 296\n",
            "length of test set : 445\n",
            "#anomaly in test set : 0\n",
            "\n",
            "Dataset  55\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9358226371061844\n",
            "Precision : 0.06896551724137931\n",
            "recall : 0.8\n",
            "f_score : 0.12698412698412698\n",
            "f01_score : 0.06959517657192074\n",
            "auc : 0.8683098591549295\n",
            "specificity : 0.9366197183098591\n",
            "\n",
            "Dataset  56\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:08<00:00,  3.34it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9649941656942824\n",
            "Precision : 0.12121212121212122\n",
            "recall : 0.8\n",
            "f_score : 0.2105263157894737\n",
            "f01_score : 0.12223903177004539\n",
            "auc : 0.882981220657277\n",
            "specificity : 0.965962441314554\n",
            "\n",
            "Dataset  57\n",
            "length of training set : 576\n",
            "length of test set : 865\n",
            "#anomaly in test set : 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9433526011560693\n",
            "Precision : 0.0\n",
            "recall : 0.0\n",
            "f_score : 0.0\n",
            "f01_score : 0\n",
            "auc : 0.4733178654292343\n",
            "specificity : 0.9466357308584686\n",
            "\n",
            "Dataset  58\n",
            "length of training set : 574\n",
            "length of test set : 861\n",
            "#anomaly in test set : 43\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9988385598141696\n",
            "Precision : 1.0\n",
            "recall : 0.9767441860465116\n",
            "f_score : 0.988235294117647\n",
            "f01_score : 0.9997643176997407\n",
            "auc : 0.9883720930232558\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  59\n",
            "length of training set : 569\n",
            "length of test set : 854\n",
            "#anomaly in test set : 0\n",
            "\n",
            "Dataset  60\n",
            "length of training set : 584\n",
            "length of test set : 877\n",
            "#anomaly in test set : 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.16it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.992018244013683\n",
            "Precision : 1.0\n",
            "recall : 0.36363636363636365\n",
            "f_score : 0.5333333333333333\n",
            "f01_score : 0.9829683698296837\n",
            "auc : 0.6818181818181819\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  61\n",
            "length of training set : 576\n",
            "length of test set : 865\n",
            "#anomaly in test set : 24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:08<00:00,  3.33it/s]\n",
            "  3%|▎         | 1/30 [00:00<00:04,  6.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9341040462427745\n",
            "Precision : 0.02857142857142857\n",
            "recall : 0.041666666666666664\n",
            "f_score : 0.03389830508474576\n",
            "f01_score : 0.028660612939841085\n",
            "auc : 0.5006193024177567\n",
            "specificity : 0.9595719381688466\n",
            "\n",
            "Dataset  62\n",
            "length of training set : 296\n",
            "length of test set : 445\n",
            "#anomaly in test set : 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:04<00:00,  6.67it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9955056179775281\n",
            "Precision : 0.6666666666666666\n",
            "recall : 1.0\n",
            "f_score : 0.8\n",
            "f01_score : 0.6688741721854305\n",
            "auc : 0.997732426303855\n",
            "specificity : 0.9954648526077098\n",
            "\n",
            "Dataset  63\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9837962962962963\n",
            "Precision : 0.35\n",
            "recall : 0.875\n",
            "f_score : 0.4999999999999999\n",
            "f01_score : 0.3520916334661355\n",
            "auc : 0.9299065420560748\n",
            "specificity : 0.9848130841121495\n",
            "\n",
            "Dataset  64\n",
            "length of training set : 576\n",
            "length of test set : 865\n",
            "#anomaly in test set : 0\n",
            "\n",
            "Dataset  65\n",
            "length of training set : 569\n",
            "length of test set : 855\n",
            "#anomaly in test set : 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9777777777777777\n",
            "Precision : 0.4166666666666667\n",
            "recall : 0.29411764705882354\n",
            "f_score : 0.3448275862068966\n",
            "f01_score : 0.4149548069022186\n",
            "auc : 0.6428822125508915\n",
            "specificity : 0.9916467780429594\n",
            "\n",
            "Dataset  66\n",
            "length of training set : 569\n",
            "length of test set : 855\n",
            "#anomaly in test set : 21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:08<00:00,  3.37it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9976608187134502\n",
            "Precision : 1.0\n",
            "recall : 0.9047619047619048\n",
            "f_score : 0.9500000000000001\n",
            "f01_score : 0.9989588755856326\n",
            "auc : 0.9523809523809523\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  67\n",
            "length of training set : 569\n",
            "length of test set : 854\n",
            "#anomaly in test set : 23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9929742388758782\n",
            "Precision : 1.0\n",
            "recall : 0.7391304347826086\n",
            "f_score : 0.85\n",
            "f01_score : 0.9965177016831108\n",
            "auc : 0.8695652173913043\n",
            "specificity : 1.0\n",
            "Avg Accuracy : 0.9712094510401154\n",
            "Avg Precision : 0.6996737013186499\n",
            "Avg recall : 0.5994888764637065\n",
            "Avg f_score : 0.5654411360093204\n",
            "Avg f01_score : 0.6919217134382012\n",
            "Avg auc : 0.7946430032432271\n",
            "Avg specificity : 0.9897971300227478\n",
            "--- 9.155613319079082 minutes ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaMNLvxzdhZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vg Accuracy : 0.9715250877309947\n",
        "# Avg Precision : 0.6842294223192591\n",
        "# Avg recall : 0.6168679144660715\n",
        "# Avg f_score : 0.5638775878595538\n",
        "# Avg f01_score : 0.6769198146771511\n",
        "# Avg auc : 0.8034431133745205\n",
        "# Avg specificity : 0.99001831228297\n",
        "# --- 9.138245284557343 minutes ---"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIezsrtqVcT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = CLSTMED(num_epochs=30, sequence_length=10, hidden_size=25, n_layers=(2, 2), dropout=(0, 0)) #57 708 recall 618\n",
        "# pytorch_total_params = sum(p.numel() for p in model.clstmed.parameters() if p.requires_grad)\n",
        "# print(pytorch_total_params)\n",
        "\n",
        "# pytorch_total_params = sum(p.numel() for p in model.clstmed.parameters())\n",
        "# print(pytorch_total_params)"
      ],
      "execution_count": 58,
      "outputs": []
    }
  ]
}