{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "thesis_lstm-ae-pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdbwkR9kiTJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import abc\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class Algorithm(metaclass=abc.ABCMeta):\n",
        "    def __init__(self, module_name, name, seed, details=False):\n",
        "        self.logger = logging.getLogger(module_name)\n",
        "        self.name = name\n",
        "        self.seed = seed\n",
        "        self.details = details\n",
        "        self.prediction_details = {}\n",
        "        self.history = {}\n",
        "\n",
        "        if self.seed is not None:\n",
        "            random.seed(seed)\n",
        "            np.random.seed(seed)\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.name\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def fit(self, X):\n",
        "        \"\"\"\n",
        "        Train the algorithm on the given dataset\n",
        "        \"\"\"\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        :return anomaly score\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "class PyTorchUtils(metaclass=abc.ABCMeta):\n",
        "    def __init__(self, seed, gpu):\n",
        "        self.gpu = gpu\n",
        "        self.seed = seed\n",
        "        if self.seed is not None:\n",
        "            torch.manual_seed(self.seed)\n",
        "            torch.cuda.manual_seed(self.seed)\n",
        "        self.framework = 0\n",
        "\n",
        "    @property\n",
        "    def device(self):\n",
        "        return torch.device('cuda:{self.gpu}' if torch.cuda.is_available() and self.gpu is not None else 'cpu')\n",
        "\n",
        "    def to_var(self, t, **kwargs):\n",
        "        # ToDo: check whether cuda Variable.\n",
        "        t = t.to(self.device)\n",
        "        return Variable(t, **kwargs)\n",
        "\n",
        "    def to_device(self, model):\n",
        "        model.to(self.device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oyfKHPLtzG-s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7137173f-1ad8-490b-f451-c636fccd911e"
      },
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from scipy.stats import multivariate_normal\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from tqdm import trange\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "!git clone https://github.com/priyojitk/mit-resources.git yahoo_dataset\n",
        "file_path = '/content/yahoo_dataset/'\n",
        "\n",
        "import sys\n",
        "sys.path.append(file_path)\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'yahoo_dataset' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "if5-euOwzG-0",
        "colab": {}
      },
      "source": [
        "\n",
        "class LSTMEDModule(nn.Module):\n",
        "    def __init__(self, n_features: int, hidden_size: int, n_layers: tuple, dropout: tuple):\n",
        "        super().__init__()\n",
        "        self.n_features = n_features\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_lyers = n_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.encoder = nn.LSTM(self.n_features, self.hidden_size, batch_first=True, num_layers=self.num_lyers[0], dropout=self.dropout[0], bias = True)\n",
        "        self.decoder = nn.LSTM(self.hidden_size, self.n_features, batch_first=True, num_layers=self.num_lyers[1], dropout=self.dropout[1], bias = True)\n",
        "\n",
        "    def forward(self, input):\n",
        "        sequence_length = input.shape[1]\n",
        "     \n",
        "        encoded, (last_hidden, _) = self.encoder(input.float())\n",
        "        decoder_input = encoded[:, -1:].repeat(1, sequence_length, 1)\n",
        "        decoded, _ = self.decoder(decoder_input)  \n",
        "\n",
        "        return decoded"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "94DqBnDbzG-6",
        "colab": {}
      },
      "source": [
        "class LSTMED(Algorithm, PyTorchUtils):\n",
        "    def __init__(self, name: str = 'LSTM-ED',\n",
        "                 num_epochs: int = 10, \n",
        "                 batch_size: int = 20, \n",
        "                 lr: float = 1e-3,\n",
        "                 hidden_size: int = 5,\n",
        "                 sequence_length: int = 48,\n",
        "                 train_gaussian_percentage: float = 0.2,\n",
        "                 n_layers: tuple = (1, 1), \n",
        "                 use_bias: tuple = (True, True),\n",
        "                 dropout: tuple = (0, 0),\n",
        "                 seed: int = 1,\n",
        "                 gpu: int = None,\n",
        "                 details=True):\n",
        "        \n",
        "        Algorithm.__init__(self, __name__, name, seed, details=details)\n",
        "\n",
        "        if self.seed is not None:\n",
        "            random.seed(seed)\n",
        "            np.random.seed(seed)\n",
        "        \n",
        "        \n",
        "        PyTorchUtils.__init__(self, seed, gpu)\n",
        "        \n",
        "        self.num_epochs = num_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.lr = lr\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.sequence_length = sequence_length\n",
        "        self.train_gaussian_percentage = train_gaussian_percentage\n",
        "\n",
        "        self.n_layers = n_layers\n",
        "        self.use_bias = use_bias\n",
        "        self.dropout = dropout\n",
        "        self.mean, self.cov = None, None\n",
        "\n",
        "        # self.lstmed = LSTMEDModule(1, self.hidden_size, self.n_layers, self.dropout)\n",
        "\n",
        "\n",
        "    def fit(self, X: pd.DataFrame):\n",
        "        \n",
        "        X.interpolate(inplace=True) #\n",
        "        X.bfill(inplace=True) #backward fill values\n",
        "        data = X.values\n",
        "        sequences = [data[i:i + self.sequence_length] for i in range(data.shape[0] - self.sequence_length + 1)]\n",
        "        indices = np.random.permutation(len(sequences)) \n",
        "        \n",
        "        split_point = int(self.train_gaussian_percentage * len(sequences))\n",
        "        train_loader = DataLoader(dataset=sequences, batch_size=self.batch_size, drop_last=True,\n",
        "                                  sampler=SubsetRandomSampler(indices[:-split_point]), pin_memory=True)\n",
        "        train_gaussian_loader = DataLoader(dataset=sequences, batch_size=self.batch_size, drop_last=True,\n",
        "                                           sampler=SubsetRandomSampler(indices[-split_point:]), pin_memory=True)\n",
        "\n",
        "        self.lstmed = LSTMEDModule(X.shape[1], self.hidden_size, self.n_layers, self.dropout)\n",
        "        self.to_device(self.lstmed)\n",
        "        optimizer = torch.optim.Adam(self.lstmed.parameters(), lr=self.lr)\n",
        "\n",
        "        self.lstmed.train() #set to training mode=True\n",
        "        self.history['train_loss'] = []\n",
        "        self.history['val_loss'] = []\n",
        "        \n",
        "        for epoch in trange(self.num_epochs): #self.num_epochs\n",
        "            self.logger.debug(f'Epoch {epoch+1}/{self.num_epochs}.')\n",
        "            self.lstmed.train() #set to training mode=True\n",
        "            train_batch_loss = []\n",
        "            for ts_batch in train_loader:\n",
        "                output = self.lstmed(self.to_var(ts_batch))\n",
        "                loss = nn.MSELoss(reduction='mean')(output, self.to_var(ts_batch.float())) \n",
        "                self.lstmed.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                train_batch_loss.append(loss.item())\n",
        "            train_loss = sum(train_batch_loss)/len(train_batch_loss)\n",
        "            self.history['train_loss'].append(train_loss)\n",
        "        \n",
        "\n",
        "            self.lstmed.eval()\n",
        "            val_batch_loss = []\n",
        "            for ts_batch in train_gaussian_loader:\n",
        "                output = self.lstmed(self.to_var(ts_batch))\n",
        "                val_loss = nn.MSELoss(reduction='mean')(output, self.to_var(ts_batch.float())) \n",
        "                val_batch_loss.append(val_loss.item())\n",
        "            self.history['val_loss'].append(sum(val_batch_loss)/len(val_batch_loss))\n",
        "\n",
        "        self.lstmed.eval()\n",
        "        error_vectors = []\n",
        "        count = 0\n",
        "        for ts_batch in train_gaussian_loader:\n",
        "            output = self.lstmed(self.to_var(ts_batch))\n",
        "            error = nn.L1Loss(reduction='none')(output, self.to_var(ts_batch.float())) #MAE\n",
        "            error_vectors += list(error.reshape(-1, X.shape[1]).data.cpu().numpy())\n",
        "            \n",
        "        self.mean = np.mean(error_vectors, axis=0)\n",
        "        self.cov = np.cov(error_vectors, rowvar=False)\n",
        "\n",
        "    def predict(self, X: pd.DataFrame):\n",
        "        X.interpolate(inplace=True)\n",
        "        X.bfill(inplace=True)\n",
        "        data = X.values\n",
        "        sequences = [data[i:i + self.sequence_length] for i in range(data.shape[0] - self.sequence_length + 1)]\n",
        "        data_loader = DataLoader(dataset=sequences, batch_size=self.batch_size, shuffle=False, drop_last=False)\n",
        "\n",
        "        self.lstmed.eval()\n",
        "        mvnormal = multivariate_normal(self.mean, self.cov, allow_singular=True)\n",
        "        scores = []\n",
        "        outputs = []\n",
        "        errors = []\n",
        "        for idx, ts in enumerate(data_loader):\n",
        "            output = self.lstmed(self.to_var(ts))\n",
        "            error = nn.L1Loss(reduction='none')(output, self.to_var(ts.float()))\n",
        "            score = -mvnormal.logpdf(error.reshape(-1, X.shape[1]).data.cpu().numpy())\n",
        "            scores.append(score.reshape(ts.size(0), self.sequence_length)) #ts.size() == batch size\n",
        "            if self.details:\n",
        "                outputs.append(output.data.numpy())\n",
        "                errors.append(error.data.numpy())\n",
        "\n",
        "        # stores seq_len-many scores per timestamp and averages them\n",
        "        scores = np.concatenate(scores)\n",
        "        lattice = np.full((self.sequence_length, data.shape[0]), np.nan)\n",
        "        for i, score in enumerate(scores):\n",
        "            lattice[i % self.sequence_length, i:i + self.sequence_length] = score\n",
        "        scores = np.nanmean(lattice, axis=0)\n",
        "\n",
        "        return scores"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UXBujS9uzHAr",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, fbeta_score\n",
        "from sklearn.metrics import precision_recall_fscore_support as prf\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "\n",
        "def get_accuracy_precision_recall_fscore(y_true: list, y_pred: list):\n",
        "        accuracy = accuracy_score(y_true, y_pred)\n",
        "        # warn_for=() avoids log warnings for any result being zero\n",
        "        precision, recall, f_score, _ = prf(y_true, y_pred, average='binary', warn_for=())\n",
        "        if precision == 0 and recall == 0:\n",
        "            f01_score = 0\n",
        "        else:\n",
        "            f01_score = fbeta_score(y_true, y_pred, average='binary', beta=0.1)\n",
        "        return accuracy, precision, recall, f_score, f01_score\n",
        "\n",
        "# accuracy, precision, recall, f_score, f01_score = get_accuracy_precision_recall_fscore(_test['is_anomaly'], pred_y)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YUVVtkMzzHA2",
        "colab": {}
      },
      "source": [
        "def threshold(score):\n",
        "    return np.nanmean(score) + 2 * np.nanstd(score)\n",
        "def get_specificity(actual_y, pred_y):\n",
        "    tn, fp, fn, tp = confusion_matrix(actual_y, pred_y).ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "    return specificity"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-eAtrGqELpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_accuracy, avg_precision, avg_recall, avg_f_score, avg_f01_score = 0, 0, 0, 0, 0\n",
        "avg_auc = 0\n",
        "avg_specificity = 0\n",
        "A1 = 67\n",
        "no_of_dataset = A1\n",
        "zero_anomaly_test = 0"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2LVFfXEGBpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = LSTMED(num_epochs=30, sequence_length=10, hidden_size=25, n_layers=(2, 2), dropout=(0, 0)) #57 708 recall 618\n",
        "# pytorch_total_params = sum(p.numel() for p in model.lstmed.parameters() if p.requires_grad)\n",
        "# print(pytorch_total_params)\n",
        "\n",
        "# pytorch_total_params = sum(p.numel() for p in model.lstmed.parameters())\n",
        "# print(pytorch_total_params)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEJu7SJKwVCi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5a91b3c9-72a5-4050-80b6-dc36eca4802c"
      },
      "source": [
        "for ind in range(1, no_of_dataset + 1):\n",
        "\n",
        "    print('\\nDataset ', ind)\n",
        "    logging.info(f'\\n\\n=============\\n Dataset {ind} : \\n=============')\n",
        "    \n",
        "    df = pd.read_csv(f'{file_path}dataset/ydata-labeled-time-series-anomalies-v1_0/A1Benchmark/real_{ind}.csv', index_col='timestamp')\n",
        "\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    df['value'] = df['value'].astype(np.float64)\n",
        "\n",
        "    # Normalize the  data (center around 0 and scale to remove the variance).\n",
        "    scaler = StandardScaler()\n",
        "    df['value'] = scaler.fit_transform(df['value'].values.reshape(-1, 1))\n",
        "\n",
        "    len_of_data = df.shape[0]\n",
        "    _train = df[0:int(len_of_data * 0.4)] # 40 percent\n",
        "    _test = df[int(len_of_data * 0.4):] # 60 percent\n",
        "    print('length of training set :', len(_train))\n",
        "    print('length of test set :', len(_test))  \n",
        "    \n",
        "    #If there is no anomaly in 'test' data or whole data ignore the dataset\n",
        "    anomaly_count_test = len(_test[_test['is_anomaly'] == 1])\n",
        "    print('#anomaly in test set :', anomaly_count_test)\n",
        "    if anomaly_count_test == 0:\n",
        "        zero_anomaly_test += 1\n",
        "        continue\n",
        "    \n",
        "    logging.info(f'length of training set : {len(_train)}')\n",
        "    logging.info(f'length of test set : {len(_test)}')\n",
        "\n",
        "    # model = LSTMED(num_epochs=30, sequence_length=10, hidden_size=10, n_layers=(1, 1), dropout=(0, 0)) #575 p 71 recall61\n",
        "    model = LSTMED(num_epochs=30, sequence_length=10, hidden_size=25, n_layers=(2, 2), dropout=(0, 0)) #57 708 recall 618\n",
        "\n",
        "\n",
        "    model.fit(_train[['value']].copy())\n",
        "\n",
        "    # plt.figure(figsize=(20, 4))\n",
        "    # plt.title('Training loss / Val Loss')\n",
        "    # plt.plot(model.history['train_loss'], label='train_loss')\n",
        "    # plt.plot(model.history['val_loss'], label='val_loss')\n",
        "    # plt.legend()\n",
        "    # plt.show()\n",
        "\n",
        "    scores = model.predict(_test[['value']].copy())\n",
        "    th = threshold(scores)\n",
        "    pred_y = np.where(np.array(scores) > th, 1, 0) \n",
        "    # th = 0.05\n",
        "    # pred_y = np.where(np.array(scores) < th, 1, 0) \n",
        "\n",
        "    # plt.figure(figsize=(20, 4))\n",
        "    # plt.title('Pred_y / actual_anomaly')\n",
        "    # plt.plot(pred_y, label='pred_y')\n",
        "    # plt.plot(_test['is_anomaly'].values, label='actual_anomaly')\n",
        "    # plt.legend()\n",
        "    # plt.show()\n",
        "\n",
        "    accuracy, precision, recall, f_score, f01_score = get_accuracy_precision_recall_fscore(_test['is_anomaly'], pred_y)\n",
        "    auc = roc_auc_score(_test['is_anomaly'], pred_y)\n",
        "    specificity = get_specificity(_test['is_anomaly'], pred_y)\n",
        "\n",
        "    \n",
        "    print(f'Accuracy : {accuracy}')\n",
        "    print(f'Precision : {precision}')\n",
        "    print(f'recall : {recall}')\n",
        "    print(f'f_score : {f_score}')\n",
        "    print(f'f01_score : {f01_score}')\n",
        "    print(f'auc : {auc}')\n",
        "    print(f'specificity : {specificity}')\n",
        "\n",
        "    avg_accuracy += accuracy\n",
        "    avg_precision += precision\n",
        "    avg_recall += recall\n",
        "    avg_f_score += f_score\n",
        "    avg_f01_score += f01_score\n",
        "    avg_auc += auc\n",
        "    avg_specificity += specificity\n",
        "\n",
        "\n",
        "denominator = (no_of_dataset - zero_anomaly_test)\n",
        "print(f'\\nAvg Accuracy : {avg_accuracy / denominator }')\n",
        "print(f'Avg Precision : {avg_precision / denominator }')\n",
        "print(f'Avg recall : {avg_recall / denominator }')\n",
        "print(f'Avg f_score : {avg_f_score / denominator }')\n",
        "print(f'Avg f01_score : {avg_f01_score / denominator }')\n",
        "print(f'Avg auc : {avg_auc / denominator }')\n",
        "print(f'Avg specificity : {avg_specificity / denominator }')\n",
        "\n",
        "print(f\"--- {(time.time() - start_time)/60} minutes ---\" )\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset  1\n",
            "length of training set : 568\n",
            "length of test set : 852\n",
            "#anomaly in test set : 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.88it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9870892018779343\n",
            "Precision : 0.15384615384615385\n",
            "recall : 1.0\n",
            "f_score : 0.2666666666666667\n",
            "f01_score : 0.15514592933947774\n",
            "auc : 0.9935294117647059\n",
            "specificity : 0.9870588235294118\n",
            "\n",
            "Dataset  2\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.90it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9872685185185185\n",
            "Precision : 1.0\n",
            "recall : 0.3125\n",
            "f_score : 0.47619047619047616\n",
            "f01_score : 0.9786821705426356\n",
            "auc : 0.65625\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  3\n",
            "length of training set : 584\n",
            "length of test set : 877\n",
            "#anomaly in test set : 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.80it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9942987457240593\n",
            "Precision : 1.0\n",
            "recall : 0.6428571428571429\n",
            "f_score : 0.782608695652174\n",
            "f01_score : 0.9945295404814004\n",
            "auc : 0.8214285714285714\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  4\n",
            "length of training set : 569\n",
            "length of test set : 854\n",
            "#anomaly in test set : 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.96it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 1.0\n",
            "Precision : 1.0\n",
            "recall : 1.0\n",
            "f_score : 1.0\n",
            "f01_score : 1.0\n",
            "auc : 1.0\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  5\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 0\n",
            "\n",
            "Dataset  6\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.95it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9988425925925926\n",
            "Precision : 1.0\n",
            "recall : 0.875\n",
            "f_score : 0.9333333333333333\n",
            "f01_score : 0.998587570621469\n",
            "auc : 0.9375\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  7\n",
            "length of training set : 569\n",
            "length of test set : 854\n",
            "#anomaly in test set : 38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.93it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9672131147540983\n",
            "Precision : 0.8571428571428571\n",
            "recall : 0.3157894736842105\n",
            "f_score : 0.46153846153846156\n",
            "f01_score : 0.8428372739916551\n",
            "auc : 0.6566692466460269\n",
            "specificity : 0.9975490196078431\n",
            "\n",
            "Dataset  8\n",
            "length of training set : 568\n",
            "length of test set : 852\n",
            "#anomaly in test set : 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.93it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9988262910798122\n",
            "Precision : 0.9090909090909091\n",
            "recall : 1.0\n",
            "f_score : 0.9523809523809523\n",
            "f01_score : 0.9099099099099099\n",
            "auc : 0.9994061757719714\n",
            "specificity : 0.998812351543943\n",
            "\n",
            "Dataset  9\n",
            "length of training set : 584\n",
            "length of test set : 877\n",
            "#anomaly in test set : 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.81it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9931584948688712\n",
            "Precision : 1.0\n",
            "recall : 0.25\n",
            "f_score : 0.4\n",
            "f01_score : 0.9711538461538461\n",
            "auc : 0.625\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  10\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.96it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 1.0\n",
            "Precision : 1.0\n",
            "recall : 1.0\n",
            "f_score : 1.0\n",
            "f01_score : 1.0\n",
            "auc : 1.0\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  11\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.96it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9849537037037037\n",
            "Precision : 1.0\n",
            "recall : 0.3157894736842105\n",
            "f_score : 0.4799999999999999\n",
            "f01_score : 0.9789983844911146\n",
            "auc : 0.6578947368421053\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  12\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.96it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9988425925925926\n",
            "Precision : 1.0\n",
            "recall : 0.5\n",
            "f_score : 0.6666666666666666\n",
            "f01_score : 0.9901960784313726\n",
            "auc : 0.75\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  13\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.96it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9965277777777778\n",
            "Precision : 1.0\n",
            "recall : 0.6666666666666666\n",
            "f_score : 0.8\n",
            "f01_score : 0.9950738916256158\n",
            "auc : 0.8333333333333333\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  14\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 0\n",
            "\n",
            "Dataset  15\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.95it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9976851851851852\n",
            "Precision : 1.0\n",
            "recall : 0.75\n",
            "f_score : 0.8571428571428571\n",
            "f01_score : 0.9967105263157895\n",
            "auc : 0.875\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  16\n",
            "length of training set : 584\n",
            "length of test set : 877\n",
            "#anomaly in test set : 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.77it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9977194982896237\n",
            "Precision : 1.0\n",
            "recall : 0.3333333333333333\n",
            "f_score : 0.5\n",
            "f01_score : 0.9805825242718447\n",
            "auc : 0.6666666666666666\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  17\n",
            "length of training set : 569\n",
            "length of test set : 855\n",
            "#anomaly in test set : 227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.96it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.7941520467836257\n",
            "Precision : 1.0\n",
            "recall : 0.22466960352422907\n",
            "f_score : 0.3669064748201439\n",
            "f01_score : 0.9669607659095175\n",
            "auc : 0.6123348017621145\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  18\n",
            "length of training set : 584\n",
            "length of test set : 877\n",
            "#anomaly in test set : 0\n",
            "\n",
            "Dataset  19\n",
            "length of training set : 569\n",
            "length of test set : 855\n",
            "#anomaly in test set : 227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.93it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.7672514619883041\n",
            "Precision : 1.0\n",
            "recall : 0.12334801762114538\n",
            "f_score : 0.2196078431372549\n",
            "f01_score : 0.9342583415923357\n",
            "auc : 0.5616740088105727\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  20\n",
            "length of training set : 568\n",
            "length of test set : 854\n",
            "#anomaly in test set : 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.97it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.990632318501171\n",
            "Precision : 1.0\n",
            "recall : 0.1111111111111111\n",
            "f_score : 0.19999999999999998\n",
            "f01_score : 0.926605504587156\n",
            "auc : 0.5555555555555556\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  21\n",
            "length of training set : 568\n",
            "length of test set : 852\n",
            "#anomaly in test set : 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.95it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9988262910798122\n",
            "Precision : 1.0\n",
            "recall : 0.8333333333333334\n",
            "f_score : 0.9090909090909091\n",
            "f01_score : 0.9980237154150197\n",
            "auc : 0.9166666666666667\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  22\n",
            "length of training set : 568\n",
            "length of test set : 852\n",
            "#anomaly in test set : 63\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.96it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9553990610328639\n",
            "Precision : 1.0\n",
            "recall : 0.3968253968253968\n",
            "f_score : 0.5681818181818182\n",
            "f01_score : 0.9851736246586031\n",
            "auc : 0.6984126984126984\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  23\n",
            "length of training set : 568\n",
            "length of test set : 852\n",
            "#anomaly in test set : 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.98it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9953051643192489\n",
            "Precision : 0.6923076923076923\n",
            "recall : 1.0\n",
            "f_score : 0.8181818181818181\n",
            "f01_score : 0.6944232238349884\n",
            "auc : 0.9976275207591934\n",
            "specificity : 0.9952550415183867\n",
            "\n",
            "Dataset  24\n",
            "length of training set : 584\n",
            "length of test set : 877\n",
            "#anomaly in test set : 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.80it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 1.0\n",
            "Precision : 1.0\n",
            "recall : 1.0\n",
            "f_score : 1.0\n",
            "f01_score : 1.0\n",
            "auc : 1.0\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  25\n",
            "length of training set : 574\n",
            "length of test set : 861\n",
            "#anomaly in test set : 43\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.92it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9988385598141696\n",
            "Precision : 1.0\n",
            "recall : 0.9767441860465116\n",
            "f_score : 0.988235294117647\n",
            "f01_score : 0.9997643176997407\n",
            "auc : 0.9883720930232558\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  26\n",
            "length of training set : 574\n",
            "length of test set : 861\n",
            "#anomaly in test set : 75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.83it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.8908246225319396\n",
            "Precision : 0.0\n",
            "recall : 0.0\n",
            "f_score : 0.0\n",
            "f01_score : 0\n",
            "auc : 0.48791348600508905\n",
            "specificity : 0.9758269720101781\n",
            "\n",
            "Dataset  27\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.94it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 1.0\n",
            "Precision : 1.0\n",
            "recall : 1.0\n",
            "f_score : 1.0\n",
            "f01_score : 1.0\n",
            "auc : 1.0\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  28\n",
            "length of training set : 576\n",
            "length of test set : 865\n",
            "#anomaly in test set : 81\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.91it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.8682080924855491\n",
            "Precision : 0.02857142857142857\n",
            "recall : 0.012345679012345678\n",
            "f_score : 0.017241379310344827\n",
            "f01_score : 0.02820441217537001\n",
            "auc : 0.4844891660367851\n",
            "specificity : 0.9566326530612245\n",
            "\n",
            "Dataset  29\n",
            "length of training set : 576\n",
            "length of test set : 865\n",
            "#anomaly in test set : 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.92it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9942196531791907\n",
            "Precision : 0.5714285714285714\n",
            "recall : 0.6666666666666666\n",
            "f_score : 0.6153846153846153\n",
            "f01_score : 0.5722379603399433\n",
            "auc : 0.8315871168024834\n",
            "specificity : 0.9965075669383003\n",
            "\n",
            "Dataset  30\n",
            "length of training set : 584\n",
            "length of test set : 877\n",
            "#anomaly in test set : 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:08<00:00,  3.75it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9988597491448119\n",
            "Precision : 1.0\n",
            "recall : 0.875\n",
            "f_score : 0.9333333333333333\n",
            "f01_score : 0.998587570621469\n",
            "auc : 0.9375\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  31\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.97it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9428238039673279\n",
            "Precision : 0.29508196721311475\n",
            "recall : 0.75\n",
            "f_score : 0.42352941176470593\n",
            "f01_score : 0.2968647942521228\n",
            "auc : 0.8491896758703482\n",
            "specificity : 0.9483793517406963\n",
            "\n",
            "Dataset  32\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 47\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.91it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9183197199533255\n",
            "Precision : 0.3333333333333333\n",
            "recall : 0.48936170212765956\n",
            "f_score : 0.396551724137931\n",
            "f01_score : 0.33438894486828846\n",
            "auc : 0.7162857893354347\n",
            "specificity : 0.9432098765432099\n",
            "\n",
            "Dataset  33\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.90it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9988425925925926\n",
            "Precision : 1.0\n",
            "recall : 0.5\n",
            "f_score : 0.6666666666666666\n",
            "f01_score : 0.9901960784313726\n",
            "auc : 0.75\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  34\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.87it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9976662777129521\n",
            "Precision : 0.7777777777777778\n",
            "recall : 1.0\n",
            "f_score : 0.8750000000000001\n",
            "f01_score : 0.7794928335170892\n",
            "auc : 0.9988235294117648\n",
            "specificity : 0.9976470588235294\n",
            "\n",
            "Dataset  35\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 0\n",
            "\n",
            "Dataset  36\n",
            "length of training set : 584\n",
            "length of test set : 877\n",
            "#anomaly in test set : 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:08<00:00,  3.75it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9954389965792474\n",
            "Precision : 0.2\n",
            "recall : 1.0\n",
            "f_score : 0.33333333333333337\n",
            "f01_score : 0.20159680638722557\n",
            "auc : 0.997716894977169\n",
            "specificity : 0.9954337899543378\n",
            "\n",
            "Dataset  37\n",
            "length of training set : 573\n",
            "length of test set : 861\n",
            "#anomaly in test set : 34\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.93it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.943089430894309\n",
            "Precision : 0.17391304347826086\n",
            "recall : 0.11764705882352941\n",
            "f_score : 0.14035087719298242\n",
            "f01_score : 0.17309340188517566\n",
            "auc : 0.5473362259051141\n",
            "specificity : 0.9770253929866989\n",
            "\n",
            "Dataset  38\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.92it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9929988331388565\n",
            "Precision : 0.7142857142857143\n",
            "recall : 0.5555555555555556\n",
            "f_score : 0.6250000000000001\n",
            "f01_score : 0.7122708039492243\n",
            "auc : 0.7765985324947589\n",
            "specificity : 0.9976415094339622\n",
            "\n",
            "Dataset  39\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.93it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9964994165694282\n",
            "Precision : 1.0\n",
            "recall : 0.625\n",
            "f_score : 0.7692307692307693\n",
            "f01_score : 0.9940944881889763\n",
            "auc : 0.8125\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  40\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 80\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.91it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.8786464410735122\n",
            "Precision : 0.038461538461538464\n",
            "recall : 0.0125\n",
            "f_score : 0.01886792452830189\n",
            "f01_score : 0.03768656716417911\n",
            "auc : 0.4901624839124839\n",
            "specificity : 0.9678249678249679\n",
            "\n",
            "Dataset  41\n",
            "length of training set : 574\n",
            "length of test set : 861\n",
            "#anomaly in test set : 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.91it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9988385598141696\n",
            "Precision : 0.6666666666666666\n",
            "recall : 1.0\n",
            "f_score : 0.8\n",
            "f01_score : 0.6688741721854305\n",
            "auc : 0.9994179278230501\n",
            "specificity : 0.9988358556461001\n",
            "\n",
            "Dataset  42\n",
            "length of training set : 576\n",
            "length of test set : 864\n",
            "#anomaly in test set : 44\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.91it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9733796296296297\n",
            "Precision : 1.0\n",
            "recall : 0.4772727272727273\n",
            "f_score : 0.6461538461538462\n",
            "f01_score : 0.9892723880597014\n",
            "auc : 0.7386363636363636\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  43\n",
            "length of training set : 576\n",
            "length of test set : 864\n",
            "#anomaly in test set : 27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.93it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9722222222222222\n",
            "Precision : 1.0\n",
            "recall : 0.1111111111111111\n",
            "f_score : 0.19999999999999998\n",
            "f01_score : 0.926605504587156\n",
            "auc : 0.5555555555555556\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  44\n",
            "length of training set : 584\n",
            "length of test set : 877\n",
            "#anomaly in test set : 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:08<00:00,  3.74it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9532497149372862\n",
            "Precision : 0.046511627906976744\n",
            "recall : 1.0\n",
            "f_score : 0.08888888888888888\n",
            "f01_score : 0.04695490469549046\n",
            "auc : 0.9765714285714286\n",
            "specificity : 0.9531428571428572\n",
            "\n",
            "Dataset  45\n",
            "length of training set : 576\n",
            "length of test set : 864\n",
            "#anomaly in test set : 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.95it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 1.0\n",
            "Precision : 1.0\n",
            "recall : 1.0\n",
            "f_score : 1.0\n",
            "f01_score : 1.0\n",
            "auc : 1.0\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  46\n",
            "length of training set : 576\n",
            "length of test set : 865\n",
            "#anomaly in test set : 109\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.91it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9861271676300578\n",
            "Precision : 1.0\n",
            "recall : 0.8899082568807339\n",
            "f_score : 0.941747572815534\n",
            "f01_score : 0.9987766337037415\n",
            "auc : 0.944954128440367\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  47\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.94it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.969661610268378\n",
            "Precision : 0.1\n",
            "recall : 0.2\n",
            "f_score : 0.13333333333333333\n",
            "f01_score : 0.10049751243781095\n",
            "auc : 0.5893742621015349\n",
            "specificity : 0.9787485242030697\n",
            "\n",
            "Dataset  48\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 0\n",
            "\n",
            "Dataset  49\n",
            "length of training set : 584\n",
            "length of test set : 877\n",
            "#anomaly in test set : 0\n",
            "\n",
            "Dataset  50\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.96it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9965277777777778\n",
            "Precision : 0.7\n",
            "recall : 1.0\n",
            "f_score : 0.8235294117647058\n",
            "f01_score : 0.702085402184707\n",
            "auc : 0.998249708284714\n",
            "specificity : 0.9964994165694282\n",
            "\n",
            "Dataset  51\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.93it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9824970828471412\n",
            "Precision : 0.17647058823529413\n",
            "recall : 0.75\n",
            "f_score : 0.2857142857142857\n",
            "f01_score : 0.17781690140845074\n",
            "auc : 0.8667936694021102\n",
            "specificity : 0.9835873388042204\n",
            "\n",
            "Dataset  52\n",
            "length of training set : 572\n",
            "length of test set : 860\n",
            "#anomaly in test set : 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.94it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9941860465116279\n",
            "Precision : 1.0\n",
            "recall : 0.4444444444444444\n",
            "f_score : 0.6153846153846153\n",
            "f01_score : 0.9877750611246944\n",
            "auc : 0.7222222222222222\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  53\n",
            "length of training set : 584\n",
            "length of test set : 877\n",
            "#anomaly in test set : 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.77it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 1.0\n",
            "Precision : 1.0\n",
            "recall : 1.0\n",
            "f_score : 1.0\n",
            "f01_score : 1.0\n",
            "auc : 1.0\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  54\n",
            "length of training set : 296\n",
            "length of test set : 445\n",
            "#anomaly in test set : 0\n",
            "\n",
            "Dataset  55\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.93it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9451575262543758\n",
            "Precision : 0.08\n",
            "recall : 0.8\n",
            "f_score : 0.14545454545454545\n",
            "f01_score : 0.08071928071928072\n",
            "auc : 0.8730046948356808\n",
            "specificity : 0.9460093896713615\n",
            "\n",
            "Dataset  56\n",
            "length of training set : 570\n",
            "length of test set : 857\n",
            "#anomaly in test set : 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.93it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9626604434072346\n",
            "Precision : 0.11428571428571428\n",
            "recall : 0.8\n",
            "f_score : 0.19999999999999998\n",
            "f01_score : 0.11526390870185449\n",
            "auc : 0.8818075117370892\n",
            "specificity : 0.9636150234741784\n",
            "\n",
            "Dataset  57\n",
            "length of training set : 576\n",
            "length of test set : 865\n",
            "#anomaly in test set : 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.92it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9445086705202312\n",
            "Precision : 0.0\n",
            "recall : 0.0\n",
            "f_score : 0.0\n",
            "f01_score : 0\n",
            "auc : 0.47389791183294666\n",
            "specificity : 0.9477958236658933\n",
            "\n",
            "Dataset  58\n",
            "length of training set : 574\n",
            "length of test set : 861\n",
            "#anomaly in test set : 43\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.90it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9988385598141696\n",
            "Precision : 1.0\n",
            "recall : 0.9767441860465116\n",
            "f_score : 0.988235294117647\n",
            "f01_score : 0.9997643176997407\n",
            "auc : 0.9883720930232558\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  59\n",
            "length of training set : 569\n",
            "length of test set : 854\n",
            "#anomaly in test set : 0\n",
            "\n",
            "Dataset  60\n",
            "length of training set : 584\n",
            "length of test set : 877\n",
            "#anomaly in test set : 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.79it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.992018244013683\n",
            "Precision : 1.0\n",
            "recall : 0.36363636363636365\n",
            "f_score : 0.5333333333333333\n",
            "f01_score : 0.9829683698296837\n",
            "auc : 0.6818181818181819\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  61\n",
            "length of training set : 576\n",
            "length of test set : 865\n",
            "#anomaly in test set : 24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.96it/s]\n",
            "  3%|▎         | 1/30 [00:00<00:03,  8.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9352601156069364\n",
            "Precision : 0.029411764705882353\n",
            "recall : 0.041666666666666664\n",
            "f_score : 0.034482758620689655\n",
            "f01_score : 0.029497663551401865\n",
            "auc : 0.5012138327388029\n",
            "specificity : 0.9607609988109393\n",
            "\n",
            "Dataset  62\n",
            "length of training set : 296\n",
            "length of test set : 445\n",
            "#anomaly in test set : 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:03<00:00,  7.80it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9955056179775281\n",
            "Precision : 0.6666666666666666\n",
            "recall : 1.0\n",
            "f_score : 0.8\n",
            "f01_score : 0.6688741721854305\n",
            "auc : 0.997732426303855\n",
            "specificity : 0.9954648526077098\n",
            "\n",
            "Dataset  63\n",
            "length of training set : 575\n",
            "length of test set : 864\n",
            "#anomaly in test set : 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.91it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9837962962962963\n",
            "Precision : 0.35\n",
            "recall : 0.875\n",
            "f_score : 0.4999999999999999\n",
            "f01_score : 0.3520916334661355\n",
            "auc : 0.9299065420560748\n",
            "specificity : 0.9848130841121495\n",
            "\n",
            "Dataset  64\n",
            "length of training set : 576\n",
            "length of test set : 865\n",
            "#anomaly in test set : 0\n",
            "\n",
            "Dataset  65\n",
            "length of training set : 569\n",
            "length of test set : 855\n",
            "#anomaly in test set : 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.90it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9777777777777777\n",
            "Precision : 0.4166666666666667\n",
            "recall : 0.29411764705882354\n",
            "f_score : 0.3448275862068966\n",
            "f01_score : 0.4149548069022186\n",
            "auc : 0.6428822125508915\n",
            "specificity : 0.9916467780429594\n",
            "\n",
            "Dataset  66\n",
            "length of training set : 569\n",
            "length of test set : 855\n",
            "#anomaly in test set : 21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.92it/s]\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9976608187134502\n",
            "Precision : 1.0\n",
            "recall : 0.9047619047619048\n",
            "f_score : 0.9500000000000001\n",
            "f01_score : 0.9989588755856326\n",
            "auc : 0.9523809523809523\n",
            "specificity : 1.0\n",
            "\n",
            "Dataset  67\n",
            "length of training set : 569\n",
            "length of test set : 854\n",
            "#anomaly in test set : 23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:07<00:00,  3.94it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9918032786885246\n",
            "Precision : 1.0\n",
            "recall : 0.6956521739130435\n",
            "f_score : 0.8205128205128205\n",
            "f01_score : 0.995686999383857\n",
            "auc : 0.8478260869565217\n",
            "specificity : 1.0\n",
            "\n",
            "Avg Accuracy : 0.9719128519140602\n",
            "Avg Precision : 0.7084813910701936\n",
            "Avg recall : 0.6182131014252652\n",
            "Avg f_score : 0.5743589757635398\n",
            "Avg f01_score : 0.7009270743114889\n",
            "Avg auc : 0.8042421051804566\n",
            "Avg specificity : 0.9902711089356475\n",
            "--- 7.833815745512644 minutes ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DthUmd_Ou7h8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    }
  ]
}